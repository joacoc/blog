<!DOCTYPE html>
<html lang="en">
<link rel="stylesheet" href="styles.css">

<header>
    <h1> Falling in the real-time trap </h1>
    <h2> The behind the scenes in the streaming data world. </h2>
</header>

<body>
    <div>
        <p class="maintext">
            As far as we know. Streaming is gaining popularity since a few years ago.<br><br> [Tweet link to Confluence CEO].<br><br> Streaming is in hype. There is no doubt of that. The research industry has been talking about it for years. Just take a look to any new streaming paper and their intro is the same “[The industry is going stream because [insert reason] and goes on]”<br><br> That’s nothing new. Behind every mountain of hype there is another mountain of true. But how far are we from real time insights? Why we are stuck in near-real time? Why we can’t do real real-time? Where are the limitations of Real Time Streaming? Do we need Real real time in Analytics? <br><br>First of all for anyone who needs needs to understand how the underlaying mechanics for the streaming engines works you can take a look at this links. And if you want to have a better undestanding distributed processing papers and how batch windowing works in SQL helps too (Clickhouse Windowing blocks)<br><br> OR <br><br>First of all we need to understand how the underlaying structure of the streaming or old SQL did the windowings aggregations.<br> Let’s start with that. <br><br> <a href="https://flink.apache.org/news/2015/12/04/Introducing-windows.html">Introducing windows</a><br><br> <a href="https://arxiv.org/pdf/1802.08496.pdf"> Distributed Stream Data Processing Systems</a><br><br> <a href="https://openproceedings.org/2019/conf/edbt/EDBT19_paper_171.pdf">Efficient Window Aggregation with General Stream Slicing</a> tuple-at-a-time processing model(e.g., Apache Storm, Apache Flink, and other Apache Beam-based systems). <br><br> There are different processing models used by these frameworks. There is the tuple-at-a-time processing model used primarly by Apache Storm / Apache Flink / Apache Beam Akka Streaming and the there is Apache Spark that use RDD’s and it’s micro-batches aggregation techniques such as B-Int [3], Pairs [28], Panes [30], RA [42] and Cutty [10]. <br><br> These techniques compute partial aggregates for overlapping parts of windows and reuse these partial aggregates to compute final aggregates for overlapping windows. These intermediate results are shared among overlapping windows to prevent repeated computation [3, 28, 51] <br><br> <a href="https://ieeexplore.ieee.org/document/7530084">Benchmarking Streaming Computation Engines</a><br><br> <a href="https://github.com/yahoo/streaming-benchmarks">Streaming benchmarks</a><br><br><a href="https://www.slideshare.net/gschmutz/spark-structured-streaming-vs-kafka-streams-two-stream-processing-platforms-compared-95628104">Two processing platforms compared</a> real-time, vs near-real-time vs batch <br><br> <a href="https://docs.confluent.io/current/streams/developer-guide/dsl-api.html#hopping-time-windows">Stream DSL</a><br><br> if the backend catches every 1 second do I need 100ms sliding? Why the use of Apache Kafka? Backpressure!!!<br><br> <a href="https://databricks.com/blog/2015/07/30/diving-into-apache-spark-streamings-execution-model.html">Apache spark streaming execution model</a> <br><br>Remember that theses apps use; MapReduce! That’s why microbatch For these applications, we believe that the 0.5–2 second latency of D-Streams is adequate, as it is well below the timescale of the trends monitored. We purposely do not target applications with latency needs below a few hundred milliseconds, such as high-frequency trading <br><br> <a href="http://people.csail.mit.edu/matei/papers/2013/sosp_spark_streaming.pdf">Sosp Spark Streaming.pdf</a><br><br> <a href="https://github.com/awslabs/deequ">Awslab/deequ</a> <br><br> <a href="https://books.google.com.ar/books?id=a8wvDAAAQBAJ&pg=PT117&lpg=PT117&dq=%E2%80%9Cbulk+incremental+processing&source=bl&ots=G2yTTVICSJ&sig=ACfU3U0lOIqLjb9FrZagl8dpBvHmLbHOZQ&hl=es&sa=X&ved=2ahUKEwjS-LOblu7oAhVaHrkGHWYrCc0Q6AEwBHoECAwQAQ#v=onepage&q=%E2%80%9Cbulk%20incremental%20processing&f=false">An Architecture for Fast and General Data Processing on Large Clusters</a> RDD falls behind in latency <br><br> <a href="https://databricks.com/blog/2018/03/20/low-latency-continuous-processing-mode-in-structured-streaming-in-apache-spark-2-3-0.html">Low latency continuous processing mode in structured streaming</a><br><br> El mundo real-time es tentador, obtenemos datos analicaticos cada segundo/hora, nos parece maravilloso, pero hasta que punto lo queremos/necesitamos? Taleb menciona que cuando miramos una analitica que cambia constantemente (x. ej. Stock price) estamos mirando la varianza y no el valor final. Eso es lo que nos emociona, lo que produce subidones o bajadones animicos, recordemos que ver estos resultados que cambian constantemente no son tan necesario. No hacen bien al alma. No hay que dejarse llevar por esta tentacion. Obviamente existen casos que si o si se precisa y no por una cuestion analitica sino por una cuestion de control. Mirar un numero que varia cada segundo no tiene mucho sentido si mi cerebro no llega a procesar esa cifra. Ahora porque hablo sobre caer en esta tramp? Hace poco llegue a una obsesion que se estaba haciendo eterna. Cuando hablamos de streaming, hablamos de complejidad y performance. Xq? Por el estado, perdida de datos y delay en la espera de resultados. <br><br> <a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/operators/windows.html#useful-state-size-considerations">State size considerations</a> <br><br> Stream Processing in Batches. In contrast to our techniques, whichadopts a tuple-at-a-time processing approach, severalworks split streams in batches of data which they process in parallel [5, 27, 52]. SABER introduces window fragments to decouple slide and range of sliding windows from the batch size [27]. However, in contrast to our work, SABER does not consider aggregate sharing among queries. Balkesen et al. use panes to share aggregates among overlapping windows [5]. None of these works addresses the general applicability with respect to workload characteristi FROM EDBT PAPER
        </p>
    </div>
</body>

